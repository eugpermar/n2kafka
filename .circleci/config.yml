version: 2.1

executors:
  compose_executor:
    # Smallest circleci official image at 11/17. We don't need any tools here.
    docker:
      - image: docker/compose:1.21.2

commands:
  save_docker_images_sum:
    description: "Save docker images ID to a file"
    parameters:
      out_file:
        type: string
    steps:
      - run: >
          docker images --filter "dangling=false" \
            --format '{{.ID}} {{.Repository}} {{.Tag}}' | sort > \
            << parameters.out_file >>

  save_docker_cache:
    description: "Save docker images to cache if they have changed"
    steps:
      - run: mkdir -p /tmp/docker-cache
      - save_docker_images_sum:
          out_file: /tmp/docker-cache/docker_images.newsum
      - run:
          environment:
            - alpine_sha: alpine@sha256:46e71df1e5191ab8b8034c5189e325258ec44ea739bba1e5645cff83c9048ff1
          # Save tags & history. If you don't save both, can't re-use docker
          # cache
          command: |
            if diff /tmp/docker-cache/built-images.sum \
                    /tmp/docker-cache/docker_images.newsum; then
              exit 0
            fi

            mv /tmp/docker-cache/docker_images.newsum \
               /tmp/docker-cache/built-images.sum
            for image in \
                          "${alpine_sha}" \
                          n2k-dev:latest; do
              printf '%s\n' "${image}"
              docker history -q "${image}"
            done | \
            grep -vx '<missing>' | \
            tee /dev/stderr | \
            xargs docker save \
            | gzip > \
            /tmp/docker-cache/built-images.tgz
      - save_cache:
          key: n2k-cache-{{ .Branch }}-{{ .BuildNum }}
          paths:
            - /tmp/docker-cache/built-images.tgz

  restore_docker_cache:
    description: "Restore docker images from cache"
    steps:
      - restore_cache:
          keys:
            - n2k-cache-{{ .Branch }}-
            - n2k-cache-

      - run: |
          if [[ -f /tmp/docker-cache/built-images.tgz ]]; then
            zcat /tmp/docker-cache/built-images.tgz | docker load;
          else
            echo "NO DOCKER CACHE";
          fi
      - save_docker_images_sum:
          out_file: /tmp/docker-cache/built-images.sum

  save_binary:
    description: "Save n2kafka binary in to be used in another job"
    steps:
      - run: |
          mkdir -p "/tmp/${CIRCLE_JOB}"
          cp n2kafka "/tmp/${CIRCLE_JOB}"

jobs:
  # Check source format
  clang-format:
    docker:
      - image: alabate/clang-format
    steps:
      - checkout
      - run: |
            out="$(find . -name '*.c' -o -name '*.h' -exec bash -c \
              "diff  -Nu {} <(clang-format {} )" \;)"
            printf '%s' "$out"
            test -z "$out"

  flake8:
    docker:
      - image: alpine/flake8:3.5.0
    steps:
      - checkout
      - run: |
          flake8 tests

  # Build & prepare devel container
  build_dev:
    executor: compose_executor
    steps:
      - setup_remote_docker
      - checkout
      # Use cached n2k images if possible
      - restore_docker_cache
      # Create development environment
      - run: apk add --no-cache make
      - run:
          environment:
            DOCKER_OUTPUT_TAG: n2k-dev
            DOCKER_OUTPUT_VERSION: latest
          command: make dev-docker
      - save_docker_cache

  # (Template) execute a single command in development docker
  T_dev_run: &T_dev_run
    executor: compose_executor
    steps:
      - setup_remote_docker
      - checkout
      - restore_docker_cache
      - run: '[[ -f workspace.tgz ]] && tar xvzpf workspace.tgz || true'
      # Launch test compose
      - run:
          background: true
          command: docker-compose -f tests/docker-compose.yml up
      # Wait container start & copy
      - run: while ! docker cp . dev-container:/app; do :; done;

      # Actual commands run. Exit 255 will stop iteration
      - run: |
             printf "%s\n" "${docker_cmds}" | \
               xargs -I {} -t -n 1 docker exec dev-container sh -c '{} || exit 255'

      # Collect results
      - run:
          name: Save n2kafka binary & Makefile config for container creation
          command: |
            mkdir -p /tmp/bin/"${CIRCLE_JOB}" /tmp/config/"${CIRCLE_JOB}" &&
            docker cp dev-container:/app/n2kafka "/tmp/bin/${CIRCLE_JOB}" &&
            docker cp dev-container:/app/Makefile.config "/tmp/config/${CIRCLE_JOB}"
      - run: docker cp dev-container:/app/tests/ /tmp
      - run: docker cp dev-container:/app/coverage.out.html . || mkdir -p coverage.out.html
      - store_test_results:
          path: /tmp/tests
      - store_artifacts:
          path: coverage.out.html
      - persist_to_workspace:
          root: /tmp
          paths:
            - bin
            - config

  # Release build -> no asserts, optimizations on
  release:
    <<: *T_dev_run
    environment:
      - docker_cmds: |
          ./configure --bootstrap
          make
          env PYTEST_JOBS=5 make checks
          env PYTEST_JOBS=5 make memchecks

  # Test with assertions on
  assertions:
    <<: *T_dev_run
    environment:
      - docker_cmds: |
          ./configure --bootstrap --disable-optimization --enable-assertions
          make
          env PYTEST_JOBS=5 make checks

  coverage:
    <<: *T_dev_run
    environment:
      - PYTEST: py.test-3
      - docker_cmds: |
          ./configure --bootstrap --disable-optimization --enable-coverage
          make
          env PYTEST_JOBS=5 make checks
          env PYTEST_JOBS=5 make memchecks
          make coverage

  containers:
    docker:
      - image: google/cloud-sdk:alpine
    steps:
      - run: |
          apk add --no-cache git make binutils docker &&
          curl -s -L \
              "https://github.com/docker/compose/releases/download/1.21.2/docker-compose-$(uname -s)-$(uname -m)" \
              -o /usr/bin/docker-compose
      - setup_remote_docker
      - checkout
      - restore_docker_cache
      - attach_workspace:
          at: /tmp/workspace
      - run:
          name: Gdb container
          # Get coverage binary, it is supposed to not to have any optimization
          # enabled
          command: |
            cp /tmp/workspace/bin/coverage/n2kafka \
              /tmp/workspace/config/coverage/Makefile.config . &&

            make -t gdb-docker && \
            CIRCLE_TAG=${CIRCLE_TAG//+/.} && \
            env DOCKER_OUTPUT_TAG=gcr.io/wizzie-registry/n2kafka \
              DOCKER_OUTPUT_VERSION=${CIRCLE_TAG:-latest}.gdb \
              make gdb-docker
      - run:
          name: Valgrind container
          # Get release binary
          command: |
            cp /tmp/workspace/bin/coverage/n2kafka \
              /tmp/workspace/config/coverage/Makefile.config . &&

            make -t valgrind-docker && \
            CIRCLE_TAG=${CIRCLE_TAG//+/.} && \
            env DOCKER_OUTPUT_TAG=gcr.io/wizzie-registry/n2kafka \
              DOCKER_OUTPUT_VERSION=${CIRCLE_TAG:-latest}.valgrind \
              make valgrind-docker
      - run:
          name: Release container
          # Get release binary
          command: |
            cp /tmp/workspace/bin/coverage/n2kafka . &&
            strip ./n2kafka && \

            make -t docker && \
            CIRCLE_TAG=${CIRCLE_TAG//+/.} && \
            env DOCKER_OUTPUT_TAG=gcr.io/wizzie-registry/n2kafka \
              DOCKER_OUTPUT_VERSION=${CIRCLE_TAG:-latest} \
              make docker
      - run:
          name: Upload images to gcr
          command: |
            # Do not print passwords!
            printf '+ docker login...\n' >&2
            docker login -u $DOCKER_USER -p $DOCKER_PASS

            printf '+ docker gcloud login...\n' >&2
            GCLOUD_KEY_JSON=$(printf '%s' "$GCLOUD_SERVICE_KEY" | base64 -d)
            printf '%s' "$GCLOUD_KEY_JSON" \
              | docker login -u _json_key --password-stdin https://gcr.io

            printf '+ gcloud auth activate...\n' >&2
            # docker login -u $DOCKER_USER -p $DOCKER_PASS
            printf '%s' "$GCLOUD_KEY_JSON" | \
              gcloud auth activate-service-account --key-file=/dev/stdin

            set -x
            CIRCLE_TAG=${CIRCLE_TAG//+/.}
            gcloud config set project "$GCLOUD_PROJECT"
            gcloud auth configure-docker --quiet

            set -- '' '.gdb' '.valgrind'
            for ext in "$@"; do
              docker push -- gcr.io/wizzie-registry/n2kafka:${CIRCLE_TAG:-latest}"$ext"
              docker tag gcr.io/wizzie-registry/n2kafka:${CIRCLE_TAG:-latest}"$ext" \
                         wizzieio/n2kafka:${CIRCLE_TAG:-latest}"$ext"
              docker push -- wizzieio/n2kafka:${CIRCLE_TAG:-latest}"$ext"
            done

#
#  # Check source code
#  static-analyzer:
#    executor: compose_executor
#    docker:
#      - image: alabate/clang-format
#    steps:
#      - setup_remote_docker
#      - run: |
#              apt update && apt install -y --no-install-recommends \
#              software-properties-common python-software-properties wget
#      - run: wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key|apt-key add -
#      - run: |
#              echo \
#              'deb http://apt.llvm.org/xenial/ llvm-toolchain-xenial-5.0 main' \
#              >> /etc/apt/sources.list
#      - run: |
#              apt update && \
#              apt install make gcc libz-dev clang-5.0 librdkafka-dev -y \
#                  --no-install-recommends
#      - run: docker cp static_analyzer:/app /home/circleci/workspace
#      - run: |
#              cd /home/circleci/workspace; \
#              find src/ -name '*.o' -delete; make src/version.h; \
#              scan-build-5.0 --status-bugs -o /tmp/scan-build make \
#              $(find src -name '*.c' -print | sed 's/\.c/\.o/;')
#
#      - store_artifacts:
#          path: /tmp/scan-build

# Need to mark all jobs needed to build containers
filter_version_tag: &filter_version_tag
  # Start with version-like
  filters: &version_tag_filter
    tags:
      only: /^[0-9]+\.[0-9]+\.[0-9]+.*/

uses_build_dev_workspace: &uses_build_dev_workspace
  requires:
    - build_dev

workflows:
  version: 2
  binary:
    jobs:
      - clang-format
      - flake8

      # Base docker for build and tests application
      - build_dev:
          <<: *filter_version_tag

      - assertions:
          <<: *uses_build_dev_workspace

      - release:
          <<: *uses_build_dev_workspace
          <<: *filter_version_tag

      - coverage:
          <<: *uses_build_dev_workspace
          <<: *filter_version_tag

      #- checks:
      #    requires:
      #      - make

      - containers:
          requires:
            - coverage
            - release
          filters:
            <<: *version_tag_filter
            branches:
              only: master
